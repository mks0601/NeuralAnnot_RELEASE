
# **NeuralAnnot: Neural Annotator for 3D Human Mesh Training Sets**
  
## Introduction  
This repo provides 3D pseudo-GTs (SMPL/MANO/FLAME/SMPL-X parameters) of various datasets, obtained by **[NeuralAnnot (CVPRW 2022 Oral.)](https://arxiv.org/abs/2011.11232)**.
We additionally provide 3D pseudo-GTs of SMPL parameters of MSCOCO, obtained by **[Three Recipes for Better 3D Pseudo-GTs of 3D Human Mesh Estimation in the Wild (CVPRW 2023)](https://arxiv.org/abs/2304.04875)**.
You need to install [smplx](https://github.com/vchoutas/smplx).

  
## Human3.6M
* [[data](https://1drv.ms/f/s!All7gdNh7XE5kGrEdXkTKN3qWOmg?e=9NK66J)]
* [[SMPL parameters](https://1drv.ms/f/s!All7gdNh7XE5oRb-ZscrxlS75Ogb?e=EaFfQz)]
* [[SMPL-X parameters](https://1drv.ms/f/s!All7gdNh7XE5oQ-E-cnOwnQC7ULH?e=lJr5Cu)]

## MPI-INF-3DHP
* [[data](https://1drv.ms/f/s!All7gdNh7XE5kHg4RvaNVUo044UI?e=nv4Ljp)]
* [[SMPL parameters](https://1drv.ms/u/s!All7gdNh7XE5oREEmLHSgZC7H2FJ?e=gHiawa)]
* [[SMPL-X parameters](https://1drv.ms/u/s!All7gdNh7XE5oQ2J3nc4WBx3dMsP?e=7mhia6)]

## MSCOCO
* [[data](https://github.com/jin-s13/COCO-WholeBody)]
* [[SMPL parameters](https://1drv.ms/u/s!All7gdNh7XE5oXhoWkhBYo5dxJ5L?e=PH3fDh)]
* [[MANO parameters](https://1drv.ms/u/s!All7gdNh7XE5oX4zIfSMlbXoA0Lk?e=Orzx74)]
* [[FLAME parameters](https://1drv.ms/u/s!All7gdNh7XE5oX3BotSZg7o9ywMV?e=dNX0u5)]
* [[SMPL-X parameters (whole body)](https://1drv.ms/u/s!All7gdNh7XE5oXFjl3fMSvRDcC6n?e=kz88Tt)]
* [[SMPL parameters from Three Recipes](https://1drv.ms/u/s!All7gdNh7XE5ok_MbpyXsz7Ixd2o?e=TfddnQ)]
* [[SMPL parameters from Two Recipes (without using 3DPW training set)](https://1drv.ms/u/s!All7gdNh7XE5olIHaHg8IO2-I-eb?e=c3P0n6)]

## MPII 2D Pose Dataset
* [[data](https://1drv.ms/f/s!All7gdNh7XE5lhxh0Mmwlvk8jwkP?e=xAHPN5)]
* [[SMPL parameters](https://1drv.ms/u/s!All7gdNh7XE5oT8hDlseabdcCimf?e=v5zeFG)]
* [[SMPL-X parameters](https://1drv.ms/u/s!All7gdNh7XE5oTG8Vm1UgTW1lqWt?e=qlbL8U)]

## 3DPW
* [[data](https://1drv.ms/f/s!All7gdNh7XE5lVy4n0H6ACMSpr5W?e=IQSfDd)]
* [[SMPL-X parameters](https://1drv.ms/f/s!All7gdNh7XE5ogmCs6fNhhSYEZ51?e=oiKnnZ)]

## CrowdPose
* [[SMPL parameters](https://1drv.ms/f/s!All7gdNh7XE5oWN1_Y_zbV4WPgQ4?e=qoBp1X)]

## FFHQ
* [[data](https://1drv.ms/u/s!All7gdNh7XE5lk2nE8_hICp8C2Uf?e=65SQXA)]
* [[FLAME parameters](https://1drv.ms/u/s!All7gdNh7XE5oS2_yEbH86xswF0i?e=ENtP5v)]

## InstaVariety
* [[data](https://1drv.ms/f/s!All7gdNh7XE5lXb9V-2zrqm_Lv2x?e=UnbPI7)]
* [[SMPL parameters](https://1drv.ms/f/s!All7gdNh7XE5oST2yIbUq41ZAEbp?e=HE14Ov)]

## InterHand2.6M
* [[MANO parameters](https://mks0601.github.io/InterHand2.6M/)]


## 
## Reference  
```  
@InProceedings{Moon_2022_CVPRW_NeuralAnnot,  
author = {Moon, Gyeongsik and Choi, Hongsuk and Lee, Kyoung Mu},  
title = {NeuralAnnot: Neural Annotator for 3D Human Mesh Training Sets},  
booktitle = {Computer Vision and Pattern Recognition Workshop (CVPRW)},  
year = {2022}  
}  

@InProceedings{Moon_2023_CVPRW_3Dpseudpgts,  
author = {Moon, Gyeongsik and Choi, Hongsuk and Chun, Sanghyuk and Lee, Jiyoung and Yun, Sangdoo},  
title = {Three Recipes for Better 3D Pseudo-GTs of 3D Human Mesh Estimation in the Wild},  
booktitle = {Computer Vision and Pattern Recognition Workshop (CVPRW)},  
year = {2023}  
}  
```
